{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title: Interpretability Analysis (Grad-CAM and SHAP)\n",
    "# Description: Generates Grad-CAM overlays and SHAP plots for model auditing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from src.model_architecture import FusionModel\n",
    "from src.interpretability import make_gradcam, compute_shap_for_metadata\n",
    "from src.data_loading import make_dataloaders\n",
    "from src.utils import load_checkpoint\n",
    "from src import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = FusionModel(metadata_dim=len(config.METADATA_FEATURES))\n",
    "ckpt_path = \"experiments/checkpoints/epoch10_valauc0.7290.pt\"\n",
    "load_checkpoint(ckpt_path, model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/processed/rsna_processed.csv\").sample(8, random_state=config.SEED)\n",
    "_, _, test_loader = make_dataloaders(df, df, df, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(test_loader))\n",
    "images, metas, labels, _ = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert tensors to numpy RGB [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def tensor_to_np(imgs):\n",
    "    imgs = imgs.permute(0,2,3,1).cpu().numpy()\n",
    "    imgs = (imgs - imgs.min()) / (imgs.max() - imgs.min())\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "target_layer = model.image_encoder.features.denseblock4\n",
    "make_gradcam(model, target_layer, images, tensor_to_np, \"outputs/gradcam\")\n",
    "\n",
    "print(\"✅ Grad-CAM visualizations saved to outputs/gradcam/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "background = metas[:50].numpy()\n",
    "X = metas.numpy()\n",
    "\n",
    "def model_predict(x):\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        probs, _ = model(torch.zeros(len(x), 3, 224, 224), x)\n",
    "    return probs.numpy()\n",
    "\n",
    "shap_values = compute_shap_for_metadata(model_predict, background, X)\n",
    "print(\"✅ SHAP computation complete.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
